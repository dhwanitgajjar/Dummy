# Backend Modifications for Enhanced NDA Processing
from fastapi import FastAPI, File, UploadFile, Form, Request, BackgroundTasks, HTTPException
from fastapi.responses import HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import os
import sys
import shutil
import uuid
from typing import List, Dict
import pandas as pd
from bs4 import BeautifulSoup
import json

# Add your base directory to the path (adjust as needed)
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

# Import your existing modules
from base.constants import (INPUT_DIR, OUTPUT_DIR, GPT_MODEL, MULTIPLIER, SKIP_MAX_ATTEMPTS, CLAUSES_PRESENT)
from base.llm_helper import LLMHelper
from base.file_processing import convert_and_extract_text, analyze_document_fonts
from base.break_documents_into_parts import break_the_document_into_parts, get_nda_sections_list
from base.get_nda_analysis import get_nda_review_and_amendments
from base.processing_amendments import process_amendments
from base.deduplication_of_amendments import (deduplication_of_amendments, deduplicate_amendments_reports, update_sections_list)
from base.save_to_excel import save_to_excel_with_multiple_sheets
from base.utils import preprocess_filename, html_to_clean_docx
from base.rewrite_nda_section import process_nda_sections

# Create FastAPI app
app = FastAPI(title="Enhanced NDA Processing Application with Selection")

# Mount static files (for CSS, JS, etc.)
app.mount("/static", StaticFiles(directory="static"), name="static")

# Setup templates
templates = Jinja2Templates(directory="templates")

# Ensure directories exist
os.makedirs(INPUT_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs("static", exist_ok=True)
os.makedirs("templates", exist_ok=True)

# In-memory storage for processing status and suggestions (in production, use Redis or database)
processing_status = {}
ai_suggestions_storage = {}

class AIsuggestion:
    """Class to represent an AI suggestion"""
    def __init__(self, section, original_text, suggested_text, rationale, confidence=0.5):
        self.section = section
        self.original_text = original_text
        self.suggested_text = suggested_text
        self.rationale = rationale
        self.confidence = confidence
    
    def to_dict(self):
        return {
            'section': self.section,
            'original_text': self.original_text,
            'suggested_text': self.suggested_text,
            'rationale': self.rationale,
            'confidence': self.confidence
        }

def extract_suggestions_from_processing_result(amendments_data, nda_sections):
    """
    Extract structured AI suggestions from your processing results.
    This function should be customized based on your actual data structure.
    """
    suggestions = []
    suggestion_id = 1
    
    # Example extraction - adapt this to your actual data structure
    if isinstance(amendments_data, list):
        for amendment in amendments_data:
            # Extract relevant information from each amendment
            section_name = amendment.get('section', f'Section {suggestion_id}')
            original = amendment.get('original_text', '')
            suggested = amendment.get('revised_text', amendment.get('suggested_text', ''))
            reason = amendment.get('rationale', amendment.get('reason', 'AI-generated improvement'))
            confidence = amendment.get('confidence', 0.75)
            
            if suggested and suggested != original:
                suggestion = AIsuggestion(
                    section=section_name,
                    original_text=original,
                    suggested_text=suggested,
                    rationale=reason,
                    confidence=confidence
                )
                suggestions.append(suggestion)
                suggestion_id += 1
    
    elif isinstance(amendments_data, dict):
        # Handle dictionary format
        for section_key, section_data in amendments_data.items():
            if isinstance(section_data, dict):
                original = section_data.get('original', '')
                suggested = section_data.get('revised', section_data.get('suggested', ''))
                reason = section_data.get('rationale', 'AI-generated improvement')
                confidence = section_data.get('confidence', 0.75)
                
                if suggested and suggested != original:
                    suggestion = AIsuggestion(
                        section=section_key,
                        original_text=original,
                        suggested_text=suggested,
                        rationale=reason,
                        confidence=confidence
                    )
                    suggestions.append(suggestion)
    
    return suggestions

def process_documents_with_suggestions(policy_file_path, nda_file_path, task_id):
    """
    Enhanced version of your processing workflow that extracts suggestions.
    This replaces your existing run_processing_workflow function.
    """
    try:
        # Update status
        processing_status[task_id]['status'] = 'processing'
        processing_status[task_id]['progress'] = 10
        
        # Initialize LLM helper
        llm_helper = LLMHelper()
        
        # Convert and extract text from documents
        processing_status[task_id]['progress'] = 20
        policy_text = convert_and_extract_text(policy_file_path)
        nda_text = convert_and_extract_text(nda_file_path)
        
        # Break documents into parts
        processing_status[task_id]['progress'] = 30
        policy_sections = break_the_document_into_parts(policy_text, "policy")
        nda_sections_list = get_nda_sections_list(nda_text)
        
        # Get NDA analysis and amendments
        processing_status[task_id]['progress'] = 50
        amendments_data = get_nda_review_and_amendments(
            policy_sections, nda_sections_list, llm_helper
        )
        
        # Process amendments
        processing_status[task_id]['progress'] = 70
        processed_amendments = process_amendments(amendments_data)
        
        # Extract AI suggestions from processing results
        ai_suggestions = extract_suggestions_from_processing_result(
            processed_amendments, nda_sections_list
        )
        
        # Store suggestions for this task
        ai_suggestions_storage[task_id] = [s.to_dict() for s in ai_suggestions]
        
        # Add unique IDs to suggestions
        for i, suggestion in enumerate(ai_suggestions_storage[task_id]):
            suggestion['id'] = i + 1
        
        # Continue with deduplication and final processing
        processing_status[task_id]['progress'] = 80
        deduplicated_amendments = deduplication_of_amendments(processed_amendments)
        
        # Generate initial outputs (these will be refined based on user selection)
        processing_status[task_id]['progress'] = 90
        nda_filename = os.path.basename(nda_file_path)
        preprocessed_filename = preprocess_filename(nda_filename)
        
        # Save initial results
        excel_report_path, html_with_revisions, docx_file = generate_and_save_outputs(
            deduplicated_amendments, preprocessed_filename
        )
        
        # Update status to completed
        processing_status[task_id]['status'] = 'completed'
        processing_status[task_id]['progress'] = 100
        processing_status[task_id]['files'] = {
            'excel_report': excel_report_path,
            'html_with_revisions': html_with_revisions,
            'docx_file': docx_file
        }
        processing_status[task_id]['suggestions'] = ai_suggestions_storage[task_id]
        processing_status[task_id]['preprocessed_filename'] = preprocessed_filename
        
        return True
        
    except Exception as e:
        processing_status[task_id]['status'] = 'error'
        processing_status[task_id]['error'] = str(e)
        return False

def generate_and_save_outputs(amendments_data, preprocessed_filename):
    """
    Generate and save output files.
    This is your existing function, possibly with modifications.
    """
    # Your existing implementation here
    # Return paths to generated files
    excel_report_path = os.path.join(OUTPUT_DIR, f"{preprocessed_filename}_report.xlsx")
    html_with_revisions = os.path.join(OUTPUT_DIR, f"{preprocessed_filename}_revised.html")
    docx_file = os.path.join(OUTPUT_DIR, f"{preprocessed_filename}_revised.docx")
    
    # Your existing file generation logic here...
    
    return excel_report_path, html_with_revisions, docx_file

def process_selected_suggestions_backend(task_id, selected_suggestion_ids):
    """
    Process only the selected suggestions to generate final document.
    """
    try:
        if task_id not in ai_suggestions_storage:
            raise ValueError("No suggestions found for this task")
        
        all_suggestions = ai_suggestions_storage[task_id]
        selected_suggestions = [
            s for s in all_suggestions 
            if s['id'] in selected_suggestion_ids
        ]
        
        if not selected_suggestions:
            raise ValueError("No valid suggestions selected")
        
        # Get the preprocessed filename from the original processing
        preprocessed_filename = processing_status[task_id]['preprocessed_filename']
        
        # Generate new outputs with only selected suggestions
        # You'll need to implement this based on your specific requirements
        final_excel_path, final_html_path, final_docx_path = generate_selective_outputs(
            selected_suggestions, preprocessed_filename
        )
        
        return {
            'status': 'success',
            'files': {
                'excel_report': final_excel_path,
                'html_with_revisions': final_html_path,
                'docx_file': final_docx_path
            },
            'selected_count': len(selected_suggestions),
            'total_count': len(all_suggestions)
        }
        
    except Exception as e:
        return {
            'status': 'error',
            'error': str(e)
        }

def generate_selective_outputs(selected_suggestions, preprocessed_filename):
    """
    Generate outputs with only the selected suggestions.
    You'll need to implement this based on your specific file generation logic.
    """
    # Create new filenames for selective processing
    excel_path = os.path.join(OUTPUT_DIR, f"{preprocessed_filename}_selected_report.xlsx")
    html_path = os.path.join(OUTPUT_DIR, f"{preprocessed_filename}_selected_revised.html")
    docx_path = os.path.join(OUTPUT_DIR, f"{preprocessed_filename}_selected_revised.docx")
    
    # Implement your file generation logic here
    # This should create documents with only the selected suggestions
    
    # Example implementation (you'll need to adapt this):
    # 1. Filter your original amendments data to include only selected items
    # 2. Regenerate the HTML/DOCX with only those amendments
    # 3. Update the Excel report to show only selected suggestions
    
    return excel_path, html_path, docx_path

@app.get("/", response_class=HTMLResponse)
async def read_root(request: Request):
    """Serve the main HTML page"""
    html_content = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>Enhanced NDA Processing API</title>
    </head>
    <body>
        <h1>Enhanced NDA Processing Application</h1>
        <p>Upload your Policy and NDA documents to generate AI suggestions with selection capability.</p>
        <h2>Available Endpoints:</h2>
        <ul>
            <li><strong>POST /process</strong> - Upload documents and start processing</li>
            <li><strong>GET /status/{task_id}</strong> - Check processing status</li>
            <li><strong>POST /process_selections</strong> - Process selected suggestions</li>
            <li><strong>GET /download/{filename}</strong> - Download generated files</li>
        </ul>
    </body>
    </html>
    """
    return HTMLResponse(content=html_content)

@app.post("/process")
async def process_files(
    background_tasks: BackgroundTasks,
    policy_file: UploadFile = File(...),
    nda_file: UploadFile = File(...)
):
    """Enhanced processing endpoint that generates AI suggestions"""
    
    # Generate unique task ID
    task_id = str(uuid.uuid4())
    
    # Initialize processing status
    processing_status[task_id] = {
        'status': 'started',
        'progress': 0,
        'task_id': task_id
    }
    
    try:
        # Save uploaded files
        policy_path = os.path.join(INPUT_DIR, f"{task_id}_policy_{policy_file.filename}")
        nda_path = os.path.join(INPUT_DIR, f"{task_id}_nda_{nda_file.filename}")
        
        with open(policy_path, "wb") as buffer:
            shutil.copyfileobj(policy_file.file, buffer)
        
        with open(nda_path, "wb") as buffer:
            shutil.copyfileobj(nda_file.file, buffer)
        
        # Start background processing
        background_tasks.add_task(
            process_documents_with_suggestions,
            policy_path,
            nda_path,
            task_id
        )
        
        return {"task_id": task_id, "status": "started"}
        
    except Exception as e:
        processing_status[task_id]['status'] = 'error'
        processing_status[task_id]['error'] = str(e)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/status/{task_id}")
async def get_status(task_id: str):
    """Get processing status with suggestions"""
    if task_id not in processing_status:
        raise HTTPException(status_code=404, detail="Task not found")
    
    status_data = processing_status[task_id].copy()
    
    # Include suggestions in the response when processing is complete
    if status_data['status'] == 'completed' and task_id in ai_suggestions_storage:
        status_data['suggestions'] = ai_suggestions_storage[task_id]
    
    return status_data

@app.post("/process_selections")
async def process_selections(selection_data: dict):
    """New endpoint to process user's suggestion selections"""
    
    try:
        task_id = selection_data.get('task_id')
        selected_suggestion_ids = selection_data.get('selected_suggestion_ids', [])
        
        if not task_id:
            raise HTTPException(status_code=400, detail="task_id is required")
        
        if task_id not in processing_status:
            raise HTTPException(status_code=404, detail="Task not found")
        
        if processing_status[task_id]['status'] != 'completed':
            raise HTTPException(status_code=400, detail="Original processing not completed")
        
        # Process selected suggestions
        result = process_selected_suggestions_backend(task_id, selected_suggestion_ids)
        
        if result['status'] == 'error':
            raise HTTPException(status_code=500, detail=result['error'])
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/download/{filename}")
async def download_file(filename: str):
    """Download generated files"""
    file_path = os.path.join(OUTPUT_DIR, filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="File not found")
    
    # Determine media type based on file extension
    if filename.endswith('.html'):
        media_type = 'text/html'
    elif filename.endswith('.docx'):
        media_type = 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
    elif filename.endswith('.xlsx'):
        media_type = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    else:
        media_type = 'application/octet-stream'
    
    return FileResponse(
        path=file_path,
        filename=filename,
        media_type=media_type
    )

# Optional: Cleanup endpoint to remove old files and data
@app.delete("/cleanup/{task_id}")
async def cleanup_task_data(task_id: str):
    """Clean up task data and files"""
    try:
        # Remove from memory storage
        if task_id in processing_status:
            del processing_status[task_id]
        
        if task_id in ai_suggestions_storage:
            del ai_suggestions_storage[task_id]
        
        # Remove associated files
        for filename in os.listdir(INPUT_DIR):
            if filename.startswith(task_id):
                os.remove(os.path.join(INPUT_DIR, filename))
        
        return {"status": "cleaned up", "task_id": task_id}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
